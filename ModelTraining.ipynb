{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## X, y Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#population = pd.read_pickle('/Users/rachel/Documents/UCI/Stats170A_winter2019/project/econdata/population.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#population = population.drop(columns = ['Description'])\n",
    "#population = population.sort_values(by=['State'])\n",
    "#population.columns\n",
    "#population = population.as_matrix(columns=['1999', '2000', '2001', '2002', '2003', '2004', '2005',\n",
    "#       '2006', '2007', '2008', '2009', '2010', '2011', '2012', '2013', '2014',\n",
    "#       '2015', '2016'])\n",
    "#population = population.astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#population.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### suicide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "suicide = pd.read_pickle('newdata/suicide.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009,\n",
       "            2010, 2011, 2012, 2013, 2014, 2015, 2016],\n",
       "           dtype='int64', name='Year')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "suicide = suicide.sort_values(by=['State'])\n",
    "suicide = suicide.drop(['United States'])\n",
    "suicide.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = np.array(suicide.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009,\n",
       "       2010, 2011, 2012, 2013, 2014, 2015, 2016])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "suicide = suicide.as_matrix(columns=[1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009,\n",
    "            2010, 2011, 2012, 2013, 2014, 2015, 2016])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 18)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "suicide.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "income = np.load('newdata/income.npy')\n",
    "pce = np.load('newdata/pce.npy')\n",
    "gdp = np.load('newdata/gdp.npy')\n",
    "population = np.load('newdata/population.npy')\n",
    "employ = np.load('newdata/employ.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.stack((income, pce, gdp, population), axis=0)\n",
    "X = np.swapaxes(X, 0, 1)\n",
    "X = np.swapaxes(X, 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 18, 4)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = [year for _ in range(50)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 18, 1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year = np.array(year)\n",
    "year = year.reshape(-1, 18, 1)\n",
    "year.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 90)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.concatenate((X, year), axis=(2))\n",
    "nsamples, ny, nf = X.shape\n",
    "X = X.reshape((nsamples,ny*nf))\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtr, Xte, ytr, yte = train_test_split(X, suicide, test_size=0.2, random_state=42)\n",
    "ytrain = np.argmax(ytr, axis=1)\n",
    "xtrain = np.argmax(Xtr, axis=1)\n",
    "ytest = np.argmax(yte, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X, y = make_regression(n_features=4, n_informative=2, random_state=0, shuffle=False)\n",
    "reg2 = RandomForestRegressor(max_depth=2, random_state=0, n_estimators=100)\n",
    "reg2.fit(Xtr, ytr)  \n",
    "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=2,\n",
    "           max_features='auto', max_leaf_nodes=None,\n",
    "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "           min_samples_leaf=1, min_samples_split=2,\n",
    "           min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
    "           oob_score=False, random_state=0, verbose=0, warm_start=False)\n",
    "#print(reg2.feature_importances_)\n",
    "ypred = reg2.predict(Xte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8194209781197428"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg2.score(Xte,yte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X, y = make_regression(n_features=4, n_informative=2, random_state=0, shuffle=False)\n",
    "reg2 = RandomForestRegressor(max_depth=2, random_state=0, n_estimators=100)\n",
    "reg2.fit(Xtr, ytr)  \n",
    "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=2,\n",
    "           max_features='auto', max_leaf_nodes=None,\n",
    "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "           min_samples_leaf=1, min_samples_split=2,\n",
    "           min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
    "           oob_score=False, random_state=0, verbose=0, warm_start=False)\n",
    "#print(reg2.feature_importances_)\n",
    "ypred = reg2.predict(Xte)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# encode year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:6: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(50, 18, 1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "suicide = pd.read_pickle('newdata/suicide.pkl')\n",
    "suicide = suicide.sort_values(by=['State'])\n",
    "suicide = suicide.drop(['United States'])\n",
    "suicide.columns = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18]\n",
    "year = np.array(suicide.columns)\n",
    "suicide = suicide.as_matrix(columns=[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18])\n",
    "year = [year for _ in range(50)]\n",
    "year = np.array(year)\n",
    "year = year.reshape(-1, 18, 1)\n",
    "year.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 18, 4)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "income = np.load('newdata/income.npy')\n",
    "pce = np.load('newdata/pce.npy')\n",
    "gdp = np.load('newdata/gdp.npy')\n",
    "population = np.load('newdata/population.npy')\n",
    "X = np.stack((income, pce, gdp, population), axis=0)\n",
    "X = np.swapaxes(X, 0, 1)\n",
    "X = np.swapaxes(X, 1, 2)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 90)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.concatenate((X, year), axis=(2))\n",
    "nsamples, ny, nf = X.shape\n",
    "X = X.reshape((nsamples,ny*nf))\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtr, Xte, ytr, yte = train_test_split(X, suicide, test_size=0.2, random_state=42)\n",
    "ytrain = np.argmax(ytr, axis=1)\n",
    "xtrain = np.argmax(Xtr, axis=1)\n",
    "ytest = np.argmax(yte, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X, y = make_regression(n_features=4, n_informative=2, random_state=0, shuffle=False)\n",
    "reg2 = RandomForestRegressor(max_depth=2, random_state=0, n_estimators=100)\n",
    "reg2.fit(Xtr, ytr)  \n",
    "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=2,\n",
    "           max_features='auto', max_leaf_nodes=None,\n",
    "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "           min_samples_leaf=1, min_samples_split=2,\n",
    "           min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
    "           oob_score=False, random_state=0, verbose=0, warm_start=False)\n",
    "#print(reg2.feature_importances_)\n",
    "ypred = reg2.predict(Xte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8194209781197428"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg2.score(Xte,yte)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# without year as feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:5: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "suicide = pd.read_pickle('newdata/suicide.pkl')\n",
    "suicide = suicide.sort_values(by=['State'])\n",
    "suicide = suicide.drop(['United States'])\n",
    "suicide.columns = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18]\n",
    "suicide = suicide.as_matrix(columns=[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 18, 4)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "income = np.load('newdata/income.npy')\n",
    "pce = np.load('newdata/pce.npy')\n",
    "gdp = np.load('newdata/gdp.npy')\n",
    "population = np.load('newdata/population.npy')\n",
    "X = np.stack((income, pce, gdp, population), axis=0)\n",
    "X = np.swapaxes(X, 0, 1)\n",
    "X = np.swapaxes(X, 1, 2)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 72)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nsamples, ny, nf = X.shape\n",
    "X = X.reshape((nsamples,ny*nf))\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtr, Xte, ytr, yte = train_test_split(X, suicide, test_size=0.2, random_state=42)\n",
    "ytrain = np.argmax(ytr, axis=1)\n",
    "xtrain = np.argmax(Xtr, axis=1)\n",
    "ytest = np.argmax(yte, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X, y = make_regression(n_features=4, n_informative=2, random_state=0, shuffle=False)\n",
    "reg2 = RandomForestRegressor(max_depth=2, random_state=0, n_estimators=100)\n",
    "reg2.fit(Xtr, ytr)  \n",
    "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=2,\n",
    "           max_features='auto', max_leaf_nodes=None,\n",
    "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "           min_samples_leaf=1, min_samples_split=2,\n",
    "           min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
    "           oob_score=False, random_state=0, verbose=0, warm_start=False)\n",
    "#print(reg2.feature_importances_)\n",
    "ypred = reg2.predict(Xte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8177617299256635"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg2.score(Xte,yte)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(random_state=0, solver='lbfgs',\n",
    "                          multi_class='multinomial').fit(Xtr, ytrain)\n",
    "clf.score(Xte,ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5392995313677672"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "clf = tree.DecisionTreeRegressor()\n",
    "clf = clf.fit(Xtr, ytr)\n",
    "ypred = clf.predict(Xte)\n",
    "clf.score(Xte,yte)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# adaboosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.4444079612575347"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "rng = np.random.RandomState(1)\n",
    "regr_2 = AdaBoostRegressor(DecisionTreeRegressor(max_depth=4),\n",
    "                          n_estimators=300, random_state=rng)\n",
    "regr_2.fit(Xtr, ytrain)\n",
    "regr_2.score(Xte,ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.2985299866508282"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "reg1 = GradientBoostingRegressor(random_state=1, n_estimators=10)\n",
    "reg1.fit(Xtr, ytrain)\n",
    "reg1.score(Xte,ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-139.72335526594722"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "reg = MLPRegressor(activation='logistic')\n",
    "reg.fit(Xtr,ytrain)\n",
    "reg.fit(Xte,ytest)\n",
    "reg.score(Xte,ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3695973039126836"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "reg = LinearRegression().fit(Xtr, ytr)\n",
    "reg.score(Xte, yte)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standardize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4430141,  4452173,  4467634,  4480089,  4503491,  4530729,\n",
       "         4569805,  4628981,  4672840,  4718206,  4757938,  4785448,\n",
       "         4798834,  4815564,  4830460,  4842481,  4853160,  4864745],\n",
       "       [  624779,   627963,   633714,   642337,   648414,   659286,\n",
       "          666946,   675302,   680300,   687455,   698895,   713906,\n",
       "          722038,   730399,   737045,   736307,   737547,   741504],\n",
       "       [ 5023823,  5160586,  5273477,  5396255,  5510364,  5652404,\n",
       "         5839077,  6029141,  6167681,  6280362,  6343154,  6407774,\n",
       "         6473497,  6556629,  6634999,  6733840,  6833596,  6945452],\n",
       "       [ 2651860,  2678588,  2691571,  2705927,  2724816,  2749686,\n",
       "         2781097,  2821761,  2848650,  2874554,  2896843,  2921978,\n",
       "         2940407,  2952109,  2959549,  2967726,  2978407,  2990410],\n",
       "       [33499204, 33987977, 34479458, 34871843, 35253159, 35574576,\n",
       "        35827943, 36021202, 36250311, 36604337, 36961229, 37320903,\n",
       "        37641823, 37960782, 38280824, 38625139, 38953142, 39209127],\n",
       "       [ 4226018,  4326921,  4425687,  4490406,  4528732,  4575013,\n",
       "         4631888,  4720423,  4803868,  4889730,  4972195,  5048281,\n",
       "         5121771,  5193721,  5270482,  5351218,  5452107,  5540921],\n",
       "       [ 3386401,  3411777,  3432835,  3458749,  3484336,  3496094,\n",
       "         3506956,  3517460,  3527270,  3545579,  3561807,  3579125,\n",
       "         3588023,  3594395,  3594915,  3594783,  3587509,  3578674],\n",
       "       [  774990,   786373,   795699,   806169,   818003,   830803,\n",
       "          845150,   859268,   871749,   883874,   891730,   899595,\n",
       "          907316,   915188,   923638,   932596,   941413,   949216],\n",
       "       [15759421, 16047515, 16356966, 16689370, 17004085, 17415318,\n",
       "        17842038, 18166990, 18367842, 18527305, 18652644, 18845785,\n",
       "        19093352, 19326230, 19563166, 19860330, 20224249, 20629982],\n",
       "       [ 8045965,  8227303,  8377038,  8508256,  8622793,  8769252,\n",
       "         8925922,  9155813,  9349988,  9504843,  9620846,  9711810,\n",
       "         9801578,  9901496,  9973326, 10069001, 10181111, 10304763],\n",
       "       [ 1210300,  1213519,  1225948,  1239613,  1251154,  1273569,\n",
       "         1292729,  1309731,  1315675,  1332213,  1346717,  1363963,\n",
       "         1379252,  1394905,  1408453,  1414862,  1422484,  1428105],\n",
       "       [ 1275674,  1299430,  1319962,  1340372,  1363380,  1391802,\n",
       "         1428241,  1468669,  1505105,  1534320,  1554439,  1570773,\n",
       "         1583828,  1595441,  1611530,  1631479,  1651523,  1682930],\n",
       "       [12359020, 12434161, 12488445, 12525556, 12556006, 12589773,\n",
       "        12609903, 12643955, 12695866, 12747038, 12796778, 12840762,\n",
       "        12867291, 12884119, 12898269, 12888962, 12864342, 12826895],\n",
       "       [ 6044969,  6091866,  6127760,  6155967,  6196638,  6233007,\n",
       "         6278616,  6332669,  6379599,  6424806,  6459325,  6490436,\n",
       "         6516045,  6537640,  6568367,  6593533,  6608296,  6633344],\n",
       "       [ 2917634,  2929067,  2931997,  2934234,  2941999,  2953635,\n",
       "         2964454,  2982644,  2999212,  3016734,  3032870,  3050767,\n",
       "         3066054,  3076097,  3093078,  3109504,  3121460,  3131785],\n",
       "       [ 2678338,  2693681,  2702162,  2713535,  2723004,  2734373,\n",
       "         2745299,  2762931,  2783785,  2808076,  2832704,  2858213,\n",
       "         2869035,  2885361,  2893510,  2900896,  2909502,  2911263],\n",
       "       [ 4018053,  4049021,  4068132,  4089875,  4117170,  4146101,\n",
       "         4182742,  4219239,  4256672,  4289878,  4317074,  4348200,\n",
       "         4369488,  4386381,  4404817,  4414483,  4425999,  4438229],\n",
       "       [ 4460811,  4471885,  4477875,  4497267,  4521042,  4552238,\n",
       "         4576628,  4302665,  4375581,  4435586,  4491648,  4544532,\n",
       "         4575184,  4600814,  4624577,  4644204,  4664851,  4678215],\n",
       "       [ 1266808,  1277072,  1285692,  1295960,  1306513,  1313688,\n",
       "         1318787,  1323619,  1327040,  1330509,  1329590,  1327632,\n",
       "         1328150,  1327691,  1328196,  1330760,  1328484,  1331370],\n",
       "       [ 5254509,  5311034,  5374691,  5440389,  5496269,  5546935,\n",
       "         5592379,  5627367,  5653408,  5684965,  5730388,  5788642,\n",
       "         5838991,  5887072,  5923704,  5958165,  5986717,  6004692],\n",
       "       [ 6317345,  6361104,  6397634,  6417206,  6422565,  6412281,\n",
       "         6403290,  6410084,  6431559,  6468967,  6517613,  6566431,\n",
       "         6613149,  6663158,  6713944,  6763652,  6795891,  6826022],\n",
       "       [ 9897116,  9952450,  9991120, 10015710, 10041152, 10055315,\n",
       "        10051137, 10036081, 10001284,  9946889,  9901591,  9877535,\n",
       "         9881521,  9896930,  9913349,  9930589,  9932573,  9951890],\n",
       "       [ 4873481,  4933692,  4982796,  5018935,  5053572,  5087713,\n",
       "         5119598,  5163555,  5207203,  5247018,  5281203,  5310843,\n",
       "         5345668,  5376550,  5413693,  5451522,  5482503,  5523409],\n",
       "       [ 2828408,  2848353,  2852994,  2858681,  2868312,  2889010,\n",
       "         2905943,  2904978,  2928350,  2947806,  2958774,  2970536,\n",
       "         2978470,  2983767,  2988797,  2990623,  2988693,  2988298],\n",
       "       [ 5561948,  5607285,  5641142,  5674825,  5709403,  5747741,\n",
       "         5790300,  5842704,  5887612,  5923916,  5961088,  5995976,\n",
       "         6009641,  6024081,  6040658,  6056293,  6071745,  6087203],\n",
       "       [  897507,   903773,   906961,   911667,   919630,   930009,\n",
       "          940102,   952692,   964706,   976415,   983982,   990722,\n",
       "          997221,  1003754,  1013564,  1021891,  1030503,  1040863],\n",
       "       [ 1704764,  1713820,  1719836,  1728292,  1738643,  1749370,\n",
       "         1761497,  1772693,  1783440,  1796378,  1812683,  1829536,\n",
       "         1840538,  1853323,  1865414,  1879522,  1891507,  1905924],\n",
       "       [ 1934718,  2018741,  2098399,  2173791,  2248850,  2346222,\n",
       "         2432143,  2522658,  2601072,  2653630,  2684665,  2702464,\n",
       "         2712799,  2744566,  2776972,  2819012,  2868666,  2919772],\n",
       "       [ 1222014,  1239882,  1255517,  1269089,  1279840,  1290121,\n",
       "         1298492,  1308389,  1312540,  1315906,  1316102,  1316777,\n",
       "         1319815,  1323962,  1326408,  1333223,  1336294,  1342373],\n",
       "       [ 8359592,  8430621,  8492671,  8552643,  8601402,  8634561,\n",
       "         8651974,  8661679,  8677885,  8711090,  8755602,  8799624,\n",
       "         8827783,  8845483,  8858362,  8866780,  8870869,  8874516],\n",
       "       [ 1808082,  1821204,  1831690,  1855309,  1877574,  1903808,\n",
       "         1932274,  1962137,  1990070,  2010662,  2036802,  2064588,\n",
       "         2080395,  2087549,  2092792,  2090342,  2090211,  2092789],\n",
       "       [18882725, 19001780, 19082838, 19137800, 19175939, 19171567,\n",
       "        19132610, 19104631, 19132335, 19212436, 19307066, 19400080,\n",
       "        19498514, 19574549, 19628043, 19656330, 19661411, 19641589],\n",
       "       [ 7949361,  8081614,  8210122,  8326201,  8422501,  8553152,\n",
       "         8705407,  8917270,  9118037,  9309449,  9449566,  9574293,\n",
       "         9656754,  9749123,  9843599,  9933944, 10033079, 10156679],\n",
       "       [  644259,   642023,   639062,   638168,   638817,   644705,\n",
       "          646089,   649422,   652822,   657569,   664968,   674710,\n",
       "          685136,   701116,   721999,   737382,   754022,   754353],\n",
       "       [11335454, 11363543, 11387404, 11407889, 11434788, 11452251,\n",
       "        11463320, 11481213, 11500468, 11515391, 11528896, 11539327,\n",
       "        11543463, 11548369, 11576576, 11602973, 11617850, 11635003],\n",
       "       [ 3437147,  3454365,  3467100,  3489080,  3504892,  3525233,\n",
       "         3548597,  3594090,  3634349,  3668976,  3717572,  3759632,\n",
       "         3787821,  3818600,  3853205,  3878367,  3909831,  3926769],\n",
       "       [ 3393941,  3429708,  3467937,  3513424,  3547376,  3569463,\n",
       "         3613202,  3670883,  3722417,  3768748,  3808600,  3837532,\n",
       "         3871728,  3899118,  3922908,  3964106,  4016918,  4091404],\n",
       "       [12263805, 12284173, 12298970, 12331031, 12374658, 12410722,\n",
       "        12449990, 12510809, 12563937, 12612285, 12666858, 12711158,\n",
       "        12744583, 12766827, 12776621, 12789101, 12785759, 12783538],\n",
       "       [ 1040402,  1050268,  1057142,  1065995,  1071342,  1074579,\n",
       "         1067916,  1063096,  1057315,  1055003,  1053646,  1053938,\n",
       "         1053536,  1054601,  1055122,  1056017,  1056173,  1057063],\n",
       "       [ 3974682,  4024223,  4064995,  4107795,  4150297,  4210921,\n",
       "         4270150,  4357847,  4444110,  4528996,  4589872,  4635656,\n",
       "         4671422,  4717112,  4764153,  4823793,  4892253,  4958235],\n",
       "       [  750412,   755844,   757972,   760020,   763729,   770396,\n",
       "          775493,   783033,   791623,   799124,   807067,   816165,\n",
       "          823484,   833496,   842270,   849088,   853933,   862890],\n",
       "       [ 5638706,  5703719,  5750789,  5795918,  5847812,  5910809,\n",
       "         5991057,  6088766,  6175727,  6247411,  6306019,  6355301,\n",
       "         6397410,  6451281,  6493432,  6540826,  6590808,  6645011],\n",
       "       [20558220, 20944499, 21319622, 21690325, 22030931, 22394023,\n",
       "        22778123, 23359580, 23831983, 24309039, 24801761, 25242679,\n",
       "        25646227, 26089620, 26489464, 26977142, 27486814, 27937492],\n",
       "       [ 2203482,  2244502,  2283715,  2324815,  2360137,  2401580,\n",
       "         2457719,  2525507,  2597746,  2663029,  2723421,  2775334,\n",
       "         2814216,  2853467,  2897927,  2937399,  2982497,  3042613],\n",
       "       [  604683,   609618,   612223,   615442,   617858,   619920,\n",
       "          621215,   622892,   623481,   624151,   624817,   625880,\n",
       "          626979,   626063,   626212,   625218,   625197,   623644],\n",
       "       [ 7000174,  7105817,  7198362,  7286873,  7366977,  7475575,\n",
       "         7577105,  7673725,  7751000,  7833496,  7925937,  8023680,\n",
       "         8100469,  8185229,  8253053,  8312076,  8362907,  8410946],\n",
       "       [ 5842564,  5910512,  5985722,  6052349,  6104115,  6178645,\n",
       "         6257305,  6370753,  6461587,  6562231,  6667426,  6742902,\n",
       "         6821655,  6892876,  6962906,  7052439,  7163543,  7294680],\n",
       "       [ 1811799,  1807021,  1801481,  1805414,  1812295,  1816438,\n",
       "         1820492,  1827912,  1834052,  1840310,  1847775,  1854214,\n",
       "         1856074,  1856764,  1853873,  1849467,  1841996,  1830929],\n",
       "       [ 5332666,  5373999,  5406835,  5445162,  5479203,  5514026,\n",
       "         5546166,  5577655,  5610775,  5640996,  5669264,  5690479,\n",
       "         5704755,  5719855,  5736952,  5751974,  5761406,  5772958],\n",
       "       [  491780,   494300,   494657,   500017,   503453,   509106,\n",
       "          514157,   522667,   534876,   546043,   559851,   564483,\n",
       "          567224,   576270,   582123,   582548,   585668,   584290]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 555,  583,  512,  514,  521,  541,  535,  580,  592,  604,  673,\n",
       "         679,  654,  724,  721,  715,  750,  788],\n",
       "       [  96,  137,  102,  132,  124,  155,  131,  135,  149,  169,  143,\n",
       "         164,  143,  168,  171,  167,  201,  193],\n",
       "       [ 766,  784,  767,  886,  840,  880,  945,  979, 1016,  972, 1060,\n",
       "        1093, 1160, 1156, 1163, 1244, 1276, 1271],\n",
       "       [ 336,  349,  382,  377,  374,  361,  400,  376,  402,  447,  422,\n",
       "         447,  462,  485,  516,  515,  577,  555],\n",
       "       [3077, 2969, 2831, 3228, 3397, 3368, 3206, 3334, 3602, 3775, 3823,\n",
       "        3913, 3996, 3893, 4025, 4214, 4167, 4294],\n",
       "       [ 574,  613,  722,  727,  728,  797,  800,  730,  811,  803,  941,\n",
       "         865,  913, 1052, 1007, 1083, 1093, 1168],\n",
       "       [ 274,  304,  283,  260,  272,  294,  295,  292,  271,  315,  316,\n",
       "         353,  370,  368,  330,  379,  384,  397],\n",
       "       [  86,   82,  108,   74,   94,   93,   83,   91,   95,  109,  107,\n",
       "         106,  105,  125,  122,  126,  122,  119],\n",
       "       [2029, 2086, 2314, 2338, 2297, 2389, 2347, 2440, 2587, 2740, 2858,\n",
       "        2789, 2880, 3002, 2928, 3035, 3205, 3143],\n",
       "       [ 873,  847,  935,  909,  972,  973,  924,  923,  997,  981, 1134,\n",
       "        1133, 1157, 1168, 1212, 1295, 1317, 1409],\n",
       "       [ 136,  137,  136,  120,  131,  116,  107,  120,  133,  133,  175,\n",
       "         207,  181,  190,  171,  204,  201,  174],\n",
       "       [ 181,  167,  210,  202,  217,  236,  228,  222,  223,  252,  304,\n",
       "         290,  281,  297,  308,  320,  359,  351],\n",
       "       [1020, 1003, 1139, 1145, 1011, 1028, 1086, 1010, 1108, 1198, 1177,\n",
       "        1178, 1226, 1292, 1321, 1398, 1363, 1415],\n",
       "       [ 628,  683,  715,  743,  736,  704,  745,  824,  790,  809,  828,\n",
       "         864,  881,  940,  944,  948,  960, 1034],\n",
       "       [ 305,  289,  304,  314,  352,  343,  333,  334,  322,  380,  361,\n",
       "         372,  422,  383,  447,  407,  433,  451],\n",
       "       [ 299,  325,  293,  345,  347,  370,  362,  379,  382,  337,  382,\n",
       "         401,  394,  502,  425,  455,  477,  514],\n",
       "       [ 470,  521,  495,  540,  567,  560,  566,  622,  649,  612,  592,\n",
       "         631,  675,  724,  701,  728,  776,  756],\n",
       "       [ 518,  468,  493,  499,  461,  537,  505,  492,  522,  532,  490,\n",
       "         557,  573,  567,  583,  679,  722,  677],\n",
       "       [ 175,  154,  161,  166,  137,  171,  175,  158,  191,  181,  197,\n",
       "         186,  235,  209,  245,  220,  235,  226],\n",
       "       [ 435,  474,  454,  477,  491,  500,  472,  495,  518,  507,  551,\n",
       "         502,  558,  583,  569,  606,  553,  586],\n",
       "       [ 431,  387,  426,  436,  433,  425,  480,  450,  516,  509,  530,\n",
       "         598,  585,  604,  572,  596,  642,  631],\n",
       "       [ 974,  974, 1051, 1106, 1029, 1098, 1108, 1139, 1131, 1180, 1169,\n",
       "        1263, 1221, 1261, 1295, 1354, 1410, 1364],\n",
       "       [ 437,  440,  480,  497,  497,  524,  547,  554,  572,  596,  584,\n",
       "         606,  683,  656,  678,  686,  730,  745],\n",
       "       [ 304,  294,  328,  343,  336,  350,  363,  325,  396,  409,  381,\n",
       "         388,  389,  410,  388,  380,  431,  383],\n",
       "       [ 700,  699,  725,  693,  679,  715,  727,  799,  808,  779,  860,\n",
       "         856,  933,  914,  960, 1017, 1052, 1133],\n",
       "       [ 162,  158,  175,  184,  180,  175,  206,  189,  196,  203,  219,\n",
       "         227,  232,  233,  243,  251,  272,  267],\n",
       "       [ 177,  193,  187,  201,  176,  166,  187,  202,  181,  191,  170,\n",
       "         193,  193,  232,  220,  251,  223,  246],\n",
       "       [ 404,  400,  387,  423,  434,  440,  480,  486,  471,  528,  505,\n",
       "         547,  516,  524,  541,  573,  558,  650],\n",
       "       [ 137,  131,  167,  132,  158,  133,  162,  151,  158,  179,  166,\n",
       "         196,  198,  202,  185,  247,  228,  244],\n",
       "       [ 563,  560,  588,  553,  588,  597,  536,  585,  596,  615,  557,\n",
       "         719,  689,  683,  757,  786,  789,  687],\n",
       "       [ 318,  327,  362,  349,  343,  356,  342,  352,  401,  419,  376,\n",
       "         413,  420,  442,  431,  449,  500,  471],\n",
       "       [1196, 1132, 1253, 1228, 1169, 1187, 1189, 1326, 1396, 1409, 1417,\n",
       "        1547, 1658, 1708, 1687, 1700, 1652, 1679],\n",
       "       [ 884,  971,  997,  986,  955, 1027, 1009, 1106, 1077, 1162, 1174,\n",
       "        1174, 1213, 1286, 1284, 1352, 1406, 1373],\n",
       "       [  73,   68,   79,   91,   81,   73,   92,   90,   95,   86,   90,\n",
       "         106,  106,  105,  128,  137,  124,  140],\n",
       "       [1102, 1088, 1219, 1287, 1074, 1319, 1341, 1325, 1295, 1412, 1176,\n",
       "        1439, 1465, 1542, 1526, 1491, 1650, 1707],\n",
       "       [ 492,  497,  515,  501,  476,  506,  522,  537,  531,  575,  567,\n",
       "         618,  693,  670,  665,  736,  790,  822],\n",
       "       [ 478,  493,  505,  518,  592,  555,  560,  579,  594,  572,  644,\n",
       "         685,  656,  724,  698,  782,  762,  772],\n",
       "       [1284, 1356, 1276, 1341, 1340, 1410, 1430, 1396, 1441, 1539, 1631,\n",
       "        1576, 1747, 1647, 1788, 1817, 1894, 1970],\n",
       "       [  96,   75,   88,   86,   84,   85,   71,   90,   96,  110,  118,\n",
       "         129,  101,  105,  132,  113,  127,  126],\n",
       "       [ 418,  443,  467,  440,  476,  482,  510,  524,  530,  565,  619,\n",
       "         637,  658,  673,  696,  753,  742,  815],\n",
       "       [ 103,   95,  105,   94,  102,  112,  121,  125,  102,  124,  129,\n",
       "         140,  128,  141,  147,  141,  173,  163],\n",
       "       [ 726,  730,  711,  778,  762,  792,  856,  874,  844,  973,  947,\n",
       "         943,  955,  978, 1030,  997, 1068, 1111],\n",
       "       [2005, 2053, 2225, 2311, 2363, 2300, 2418, 2347, 2433, 2552, 2809,\n",
       "        2891, 2896, 3037, 3059, 3254, 3403, 3488],\n",
       "       [ 282,  298,  321,  340,  336,  377,  348,  362,  378,  390,  449,\n",
       "         473,  502,  550,  579,  559,  630,  620],\n",
       "       [  63,   77,   72,   92,   83,   93,   78,   81,   89,   94,   87,\n",
       "         106,  120,   87,  112,  124,  103,  118],\n",
       "       [ 791,  768,  797,  799,  808,  828,  866,  876,  880,  948,  963,\n",
       "         963, 1054, 1063, 1072, 1123, 1118, 1166],\n",
       "       [ 816,  727,  712,  811,  803,  830,  822,  809,  865,  889,  921,\n",
       "         957, 1021, 1038, 1027, 1119, 1137, 1141],\n",
       "       [ 229,  245,  286,  276,  266,  285,  255,  269,  300,  261,  253,\n",
       "         279,  306,  326,  323,  359,  340,  362],\n",
       "       [ 593,  590,  639,  627,  647,  662,  643,  670,  729,  743,  724,\n",
       "         793,  745,  723,  850,  769,  877,  866],\n",
       "       [  98,   83,   83,  105,  109,   88,   90,  116,  101,  124,  111,\n",
       "         131,  132,  171,  129,  120,  157,  144]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "suicide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = np.divide(population,suicide)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdps = np.divide(population,gdp)\n",
    "employs = np.divide(employ,population)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "incomes = np.divide(population,income)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcep = np.load('newdata/pcep.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.stack((incomes, pcep, gdps, employs), axis=0)\n",
    "X = np.swapaxes(X, 0, 1)\n",
    "X = np.swapaxes(X, 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 18, 4)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 90)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.concatenate((X, year), axis=(2))\n",
    "nsamples, ny, nf = X.shape\n",
    "X = X.reshape((nsamples,ny*nf))\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtr, Xte, ytr, yte = train_test_split(X, suicide, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-143.8876162581271"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg = LinearRegression()\n",
    "reg.fit(Xtr, ytr)\n",
    "reg.score(Xtr, ytr)\n",
    "ypred = reg.predict(Xte)\n",
    "r2_score(yte, ypred) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-147.9891291034076"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.score(Xte,yte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00812059 0.01184238 0.02983717 0.00085243 0.         0.01003268\n",
      " 0.00729361 0.0062896  0.00717283 0.         0.00182099 0.00024342\n",
      " 0.00458198 0.01808347 0.         0.00573822 0.0110377  0.\n",
      " 0.0196704  0.         0.         0.00258549 0.         0.0378653\n",
      " 0.         0.0054826  0.0024845  0.00583394 0.01503408 0.\n",
      " 0.0024755  0.         0.01242638 0.05382605 0.         0.03092375\n",
      " 0.         0.00529608 0.06099523 0.         0.01146012 0.\n",
      " 0.         0.08073529 0.         0.0060167  0.00234928 0.05366761\n",
      " 0.06414474 0.         0.00863315 0.00616703 0.01025803 0.05577886\n",
      " 0.         0.03007095 0.00288252 0.00554632 0.03036718 0.\n",
      " 0.01238711 0.00132956 0.00612606 0.03707602 0.         0.00475225\n",
      " 0.00404491 0.00453233 0.00551023 0.         0.0028854  0.01018417\n",
      " 0.00773402 0.00808585 0.         0.00139268 0.00647432 0.00252313\n",
      " 0.01093033 0.         0.00858888 0.00685058 0.00579741 0.00154799\n",
      " 0.         0.03648562 0.01285592 0.02797795 0.02800316 0.        ]\n"
     ]
    }
   ],
   "source": [
    "# X, y = make_regression(n_features=4, n_informative=2, random_state=0, shuffle=False)\n",
    "reg2 = RandomForestRegressor(max_depth=2, random_state=0, n_estimators=100)\n",
    "reg2.fit(Xtr, ytr)  \n",
    "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=2,\n",
    "           max_features='auto', max_leaf_nodes=None,\n",
    "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "           min_samples_leaf=1, min_samples_split=2,\n",
    "           min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
    "           oob_score=False, random_state=0, verbose=0, warm_start=False)\n",
    "print(reg2.feature_importances_)\n",
    "ypred = reg2.predict(Xte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.2463016461014884"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg2.score(Xte,yte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.24334086312813566"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(yte, ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrain = np.argmax(ytr, axis=1)\n",
    "xtrain = np.argmax(Xtr, axis=1)\n",
    "ytest = np.argmax(yte, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.63265306122449"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(random_state=0, solver='lbfgs').fit(Xtr, ytrain)\n",
    "ypred = clf.predict(Xte)\n",
    "r2_score(ytest, ypred) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.9513964089036974"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "rng = np.random.RandomState(1)\n",
    "regr_2 = AdaBoostRegressor(DecisionTreeRegressor(max_depth=4),\n",
    "                          n_estimators=300, random_state=rng)\n",
    "regr_2.fit(Xtr, ytrain)\n",
    "regr_2.score(Xte,ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-7.953171158986925"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn = MLPRegressor()\n",
    "nn.fit(Xtr, ytr)\n",
    "nn.score(Xtr, ytr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import rand\n",
    "from numpy.random import seed\n",
    "from scipy.stats import spearmanr\n",
    "# seed random number generator\n",
    "seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 18)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pce.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 18)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "suicide.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "pce = pce.reshape(900,1)\n",
    "suicide = suicide.reshape(900,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient:  0.9397704785954204\n",
      "Samples are correlated (reject H0) p= 0.0\n"
     ]
    }
   ],
   "source": [
    "coef, p = spearmanr(pce.reshape(900,1), suicide.reshape(900,1))\n",
    "print(\"Coefficient: \",coef)\n",
    "# interpret the significance\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Samples are uncorrelated (fail to reject H0) p=', p)\n",
    "else:\n",
    "    print('Samples are correlated (reject H0) p=', p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient:  0.9333095521877787\n",
      "Samples are correlated (reject H0) p= 0.0\n"
     ]
    }
   ],
   "source": [
    "coef, p = spearmanr(income.reshape(900,1), suicide.reshape(900,1))\n",
    "print(\"Coefficient: \",coef)\n",
    "# interpret the significance\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Samples are uncorrelated (fail to reject H0) p=', p)\n",
    "else:\n",
    "    print('Samples are correlated (reject H0) p=', p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient:  0.9333717746127999\n",
      "Samples are correlated (reject H0) p= 0.0\n"
     ]
    }
   ],
   "source": [
    "coef, p = spearmanr(gdp.reshape(900,1), suicide.reshape(900,1))\n",
    "print(\"Coefficient: \",coef)\n",
    "# interpret the significance\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Samples are uncorrelated (fail to reject H0) p=', p)\n",
    "else:\n",
    "    print('Samples are correlated (reject H0) p=', p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient:  0.9491420976173418\n",
      "Samples are correlated (reject H0) p= 0.0\n"
     ]
    }
   ],
   "source": [
    "coef, p = spearmanr(employ.reshape(900,1), suicide.reshape(900,1))\n",
    "print(\"Coefficient: \",coef)\n",
    "# interpret the significance\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Samples are uncorrelated (fail to reject H0) p=', p)\n",
    "else:\n",
    "    print('Samples are correlated (reject H0) p=', p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient:  0.05227152510829885\n",
      "Samples are uncorrelated (fail to reject H0) p= 0.11710586977757245\n"
     ]
    }
   ],
   "source": [
    "coef, p = spearmanr(pcep.reshape(900,1), suicide.reshape(900,1))\n",
    "print(\"Coefficient: \",coef)\n",
    "# interpret the significance\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Samples are uncorrelated (fail to reject H0) p=', p)\n",
    "else:\n",
    "    print('Samples are correlated (reject H0) p=', p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient:  -0.1044469988562762\n",
      "Samples are correlated (reject H0) p= 0.0017031352370472056\n"
     ]
    }
   ],
   "source": [
    "coef, p = spearmanr(incomes.reshape(900,1), suicide.reshape(900,1))\n",
    "print(\"Coefficient: \",coef)\n",
    "# interpret the significance\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Samples are uncorrelated (fail to reject H0) p=', p)\n",
    "else:\n",
    "    print('Samples are correlated (reject H0) p=', p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient:  -0.11403720295276353\n",
      "Samples are correlated (reject H0) p= 0.0006090575528909936\n"
     ]
    }
   ],
   "source": [
    "coef, p = spearmanr(gdps.reshape(900,1), suicide.reshape(900,1))\n",
    "print(\"Coefficient: \",coef)\n",
    "# interpret the significance\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Samples are uncorrelated (fail to reject H0) p=', p)\n",
    "else:\n",
    "    print('Samples are correlated (reject H0) p=', p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient:  -0.45740115334132203\n",
      "Samples are correlated (reject H0) p= 9.797367131945844e-48\n"
     ]
    }
   ],
   "source": [
    "coef, p = spearmanr(employs.reshape(900,1), suicide.reshape(900,1))\n",
    "print(\"Coefficient: \",coef)\n",
    "# interpret the significance\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Samples are uncorrelated (fail to reject H0) p=', p)\n",
    "else:\n",
    "    print('Samples are correlated (reject H0) p=', p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.646959 using {'max_depth': 6, 'n_estimators': 20}\n",
      "0.375546 (0.213449) with: {'max_depth': 1, 'n_estimators': 10}\n",
      "0.395846 (0.222579) with: {'max_depth': 1, 'n_estimators': 20}\n",
      "0.395516 (0.258871) with: {'max_depth': 1, 'n_estimators': 30}\n",
      "0.350607 (0.279372) with: {'max_depth': 1, 'n_estimators': 50}\n",
      "0.342526 (0.275662) with: {'max_depth': 1, 'n_estimators': 80}\n",
      "0.335964 (0.291627) with: {'max_depth': 1, 'n_estimators': 100}\n",
      "0.347886 (0.268183) with: {'max_depth': 1, 'n_estimators': 150}\n",
      "0.543666 (0.238947) with: {'max_depth': 2, 'n_estimators': 10}\n",
      "0.598491 (0.215304) with: {'max_depth': 2, 'n_estimators': 20}\n",
      "0.597361 (0.242150) with: {'max_depth': 2, 'n_estimators': 30}\n",
      "0.576625 (0.260821) with: {'max_depth': 2, 'n_estimators': 50}\n",
      "0.562718 (0.260865) with: {'max_depth': 2, 'n_estimators': 80}\n",
      "0.559875 (0.274096) with: {'max_depth': 2, 'n_estimators': 100}\n",
      "0.548411 (0.282325) with: {'max_depth': 2, 'n_estimators': 150}\n",
      "0.584888 (0.259510) with: {'max_depth': 3, 'n_estimators': 10}\n",
      "0.603869 (0.259221) with: {'max_depth': 3, 'n_estimators': 20}\n",
      "0.615341 (0.275163) with: {'max_depth': 3, 'n_estimators': 30}\n",
      "0.602117 (0.283110) with: {'max_depth': 3, 'n_estimators': 50}\n",
      "0.596352 (0.277680) with: {'max_depth': 3, 'n_estimators': 80}\n",
      "0.595076 (0.288586) with: {'max_depth': 3, 'n_estimators': 100}\n",
      "0.586301 (0.293438) with: {'max_depth': 3, 'n_estimators': 150}\n",
      "0.591383 (0.243198) with: {'max_depth': 4, 'n_estimators': 10}\n",
      "0.609307 (0.248869) with: {'max_depth': 4, 'n_estimators': 20}\n",
      "0.625464 (0.255835) with: {'max_depth': 4, 'n_estimators': 30}\n",
      "0.611449 (0.270756) with: {'max_depth': 4, 'n_estimators': 50}\n",
      "0.600806 (0.270187) with: {'max_depth': 4, 'n_estimators': 80}\n",
      "0.596175 (0.282767) with: {'max_depth': 4, 'n_estimators': 100}\n",
      "0.585033 (0.290242) with: {'max_depth': 4, 'n_estimators': 150}\n",
      "0.598913 (0.219736) with: {'max_depth': 5, 'n_estimators': 10}\n",
      "0.617069 (0.238296) with: {'max_depth': 5, 'n_estimators': 20}\n",
      "0.628598 (0.248398) with: {'max_depth': 5, 'n_estimators': 30}\n",
      "0.607862 (0.273942) with: {'max_depth': 5, 'n_estimators': 50}\n",
      "0.601036 (0.267103) with: {'max_depth': 5, 'n_estimators': 80}\n",
      "0.594978 (0.280240) with: {'max_depth': 5, 'n_estimators': 100}\n",
      "0.588927 (0.283539) with: {'max_depth': 5, 'n_estimators': 150}\n",
      "0.620136 (0.198622) with: {'max_depth': 6, 'n_estimators': 10}\n",
      "0.646959 (0.203791) with: {'max_depth': 6, 'n_estimators': 20}\n",
      "0.636632 (0.236833) with: {'max_depth': 6, 'n_estimators': 30}\n",
      "0.616621 (0.262229) with: {'max_depth': 6, 'n_estimators': 50}\n",
      "0.599970 (0.268525) with: {'max_depth': 6, 'n_estimators': 80}\n",
      "0.592134 (0.283684) with: {'max_depth': 6, 'n_estimators': 100}\n",
      "0.584795 (0.288157) with: {'max_depth': 6, 'n_estimators': 150}\n",
      "0.617131 (0.205683) with: {'max_depth': 7, 'n_estimators': 10}\n",
      "0.645293 (0.205708) with: {'max_depth': 7, 'n_estimators': 20}\n",
      "0.635927 (0.238752) with: {'max_depth': 7, 'n_estimators': 30}\n",
      "0.617217 (0.262721) with: {'max_depth': 7, 'n_estimators': 50}\n",
      "0.602112 (0.265979) with: {'max_depth': 7, 'n_estimators': 80}\n",
      "0.596420 (0.278649) with: {'max_depth': 7, 'n_estimators': 100}\n",
      "0.587232 (0.284362) with: {'max_depth': 7, 'n_estimators': 150}\n",
      "0.610626 (0.204739) with: {'max_depth': 8, 'n_estimators': 10}\n",
      "0.645240 (0.203769) with: {'max_depth': 8, 'n_estimators': 20}\n",
      "0.635851 (0.236794) with: {'max_depth': 8, 'n_estimators': 30}\n",
      "0.617141 (0.261787) with: {'max_depth': 8, 'n_estimators': 50}\n",
      "0.600336 (0.266201) with: {'max_depth': 8, 'n_estimators': 80}\n",
      "0.594921 (0.278804) with: {'max_depth': 8, 'n_estimators': 100}\n",
      "0.586691 (0.284321) with: {'max_depth': 8, 'n_estimators': 150}\n",
      "0.610626 (0.204739) with: {'max_depth': 9, 'n_estimators': 10}\n",
      "0.645240 (0.203769) with: {'max_depth': 9, 'n_estimators': 20}\n",
      "0.635851 (0.236794) with: {'max_depth': 9, 'n_estimators': 30}\n",
      "0.617141 (0.261787) with: {'max_depth': 9, 'n_estimators': 50}\n",
      "0.600336 (0.266201) with: {'max_depth': 9, 'n_estimators': 80}\n",
      "0.594920 (0.278803) with: {'max_depth': 9, 'n_estimators': 100}\n",
      "0.586690 (0.284320) with: {'max_depth': 9, 'n_estimators': 150}\n",
      "0.610626 (0.204739) with: {'max_depth': 10, 'n_estimators': 10}\n",
      "0.645240 (0.203769) with: {'max_depth': 10, 'n_estimators': 20}\n",
      "0.635851 (0.236794) with: {'max_depth': 10, 'n_estimators': 30}\n",
      "0.617141 (0.261787) with: {'max_depth': 10, 'n_estimators': 50}\n",
      "0.600336 (0.266201) with: {'max_depth': 10, 'n_estimators': 80}\n",
      "0.594920 (0.278803) with: {'max_depth': 10, 'n_estimators': 100}\n",
      "0.586690 (0.284320) with: {'max_depth': 10, 'n_estimators': 150}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "max_depth = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "n_estimators=[10,20,30,50,80,100,150]\n",
    "\n",
    "param_grid = dict(max_depth=max_depth,n_estimators=n_estimators)\n",
    "grid = GridSearchCV(estimator=reg2, param_grid=param_grid, n_jobs=-1)\n",
    "grid_result = grid.fit(Xtr, ytr)\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X, y = make_regression(n_features=4, n_informative=2, random_state=0, shuffle=False)\n",
    "reg2 = RandomForestRegressor(max_depth=2, random_state=0, n_estimators=100)\n",
    "reg2.fit(Xtr, ytr)  \n",
    "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=6,\n",
    "           max_features='auto', max_leaf_nodes=None,\n",
    "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "           min_samples_leaf=1, min_samples_split=2,\n",
    "           min_weight_fraction_leaf=0.0, n_estimators=20, n_jobs=None,\n",
    "           oob_score=False, random_state=0, verbose=0, warm_start=False)\n",
    "#print(reg2.feature_importances_)\n",
    "ypred = reg2.predict(Xte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8194209781197428"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg2.score(Xte,yte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
